[paths]
train = ./train.spacy
dev = ./dev.spacy
vectors = ./vectors
init_tok2vec = ./init_tok2vec
output_dir = ./output

[system]
gpu_allocator = first

[nlp]
lang = en
pipeline = ["ner"]
vectors = {"@vectors": "spacy.Vectors.v1"}

[components]
ner = en_core_web_lg

[ner]
factory = "ner"

[training]
seed = 42
train_data = ./train.spacy
dev_data = ./dev.spacy
batch_size = 16
max_steps = 20000
eval_frequency = 1000
patience = 3
learning_rate = 0.001
dropout = 0.2
vector_width = 300

[components]
tokenizer = {"factory": "tokenizer", "config": {"use_fast": true}}

[pretraining]
frozen_components = ["ner"]

[before_creation]
disable = ["tagger", "parser", "textcat", "entity_ruler", "lemmatizer"]

[after_creation]
disable = ["tagger", "parser", "textcat", "entity_ruler", "lemmatizer"]

[after_pipeline_creation]
disable = ["tagger", "parser", "textcat", "entity_ruler", "lemmatizer"]
